---
title: "Biostat 625 Final Project kNN"
author: "Leyuan Qian"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Required R packages

```{r}
library(class) # package including kNN function
library(caret) # package for plotting classification models
library(pROC) # package for analyzing ROC curves
library(ROSE) # package including binary class balance techniques
library(future)
```

## Read in Train Set and Test Set

```{r}
train=read.csv("outtrain.csv",stringsAsFactors = F) # train set
test=read.csv("outtest.csv", stringsAsFactors = F) # test set
```

## Normalization by Min-Max Scaling

```{r}
# A function for normalization
normalization<-function(x){
  return (x-min(x))/(max(x)-min(x))
}
# Normalize both datasets
train_data<-as.data.frame(lapply(train[1:80],normalization))
test_data<-as.data.frame(lapply(test[1:80],normalization))
```

## kNN Modeling

### Finding the optimal value of k (number of neighbors to inspect)

```{r}
# k = odd numbers smaller than 30
for (i in seq(1,30,by=2)){
  model<-knn(train=train_data[,-1],test=test_data[,-1],cl=train_data[,1],k=i)
  conf_mat = confusionMatrix(data=as.factor(model),reference=as.factor(test_data[,1]),positive="1")
  print(conf_mat$overall["Accuracy"]);print(conf_mat$byClass["Sensitivity"]);
  print(conf_mat$byClass["Specificity"])
}
```

```{r}
# k = sqrt of total number of observations
model<-knn(train=train_data[,-1],test=test_data[,-1],
cl=train_data[,1],k=floor(sqrt(nrow(train_data))))
conf_mat=confusionMatrix(data=as.factor(model),reference=as.factor(test_data[,1]),positive="1")
conf_mat
```

### kNN modeling with k=7

```{r}
knn_model<-knn(train=train_data[,-1],test=test_data[,-1],cl=train_data[,1],k=7)
```

### Create the confusion matrix
```{r}
confusion_matrix = confusionMatrix(data=as.factor(knn_model),reference=as.factor(test_data[,1]),positive="1")
confusion_matrix 
```

## Diagnostics

### Recall
```{r}
# recall = TP/(TP+FN)
TP=sum(knn_model==1 & test_data[,1]==1)
FN=sum(knn_model==0 & test_data[,1]==1)
recall=TP/(TP+FN)
recall #0.0512
```

### Precision
```{r}
# precision = TP/(TP+FP)
FP=sum(knn_model==1 & test_data[,1]==0)
precision=TP/(TP+FP)
precision #0.521
```

### F1 score
```{r}
f1_score=2*(precision*recall)/(precision+recall)
f1_score #0.0932
```

### AUC
```{r}
auc(as.numeric(test_data[,1]), as.numeric(knn_model))
```

## kNN Modeling after Class Balancing in Train set

```{r}
# the dimension of the original train set
table(train$hospital_death) 

# Random oversampling to balance the class 
# Make two classes 1:1, each with 62823 cases
train_balanced_over <- ovun.sample(hospital_death ~ ., data = train_data, 
                                   method = "over",N=62823*2)$data
table(train_balanced_over$hospital_death) 

# Random undersampling to balance the class 
# Make two classes 1:1, each with 62823 cases
train_balanced_under <- ovun.sample(hospital_death ~ ., data = train_data, 
                                    method = "under",N=50000)$data
table(train_balanced_under$hospital_death)

# Balance the class with the combination of over- and under- sampling
train_balanced_both <- ovun.sample(hospital_death ~ ., data = train_data, 
                                   method = "both",N=50000)$data
table(train_balanced_both$hospital_death)
```

### kNN modeling after random oversampling technique

```{r}
# k = 7
knn_model_over<-knn(train=train_balanced_over[,-1],test=test_data[,-1],
                  cl=train_balanced_over[,1],k=7)
conf_mat_over = confusionMatrix(data=as.factor(knn_model_over),reference=as.factor(test_data[,1]),positive="1")
conf_mat_over

# k = sqrt of total number of observations
knn_model_over_2<-knn(train=train_balanced_over[,-1],test=test_data[,-1],
                     cl=train_balanced_over[,1],k=floor(sqrt(nrow(train_balanced_over))))
conf_mat_over_2 = confusionMatrix(data=as.factor(knn_model_over_2),reference=as.factor(test_data[,1]),positive="1")
conf_mat_over_2
```

### kNN modeling after random undersampling technique
```{r}
# k = 7
knn_model_under<-knn(train=train_balanced_under[,-1],test=test_data[,-1],
                     cl=train_balanced_under[,1],k=7)
conf_mat_under= confusionMatrix(data=as.factor(knn_model_under),reference=as.factor(test_data[,1]),positive="1")
conf_mat_under

# k = sqrt of total number of observations
knn_model_under_2<-knn(train=train_balanced_under[,-1],test=test_data[,-1],
                      cl=train_balanced_under[,1],k=floor(sqrt(nrow(train_balanced_under))))
conf_mat_under_2 = confusionMatrix(data=as.factor(knn_model_under_2),reference=as.factor(test_data[,1]),positive="1")
conf_mat_under_2
```

### kNN modeling after a combination of over- and under- sampling
```{r}
# k = 7
knn_model_both<-knn(train=train_balanced_both[,-1],test=test_data[,-1],cl=train_balanced_both[,1],k=7)
conf_mat_both= confusionMatrix(data=as.factor(knn_model_both),reference=as.factor(test_data[,1]),positive="1")
conf_mat_both

# k = sqrt of total number of observations
knn_model_both_2<-knn(train=train_balanced_both[,-1],test=test_data[,-1],
                      cl=train_balanced_both[,1],k=floor(sqrt(nrow(train_balanced_under))))
conf_mat_both_2= confusionMatrix(data=as.factor(knn_model_both_2),reference=as.factor(test_data[,1]),positive="1")
conf_mat_both_2
```
